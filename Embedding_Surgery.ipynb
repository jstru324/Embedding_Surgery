{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Qhr2M_4AI7A3",
        "outputId": "8119530e-5da2-4e75-a838-4b011ed3085a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nFile Name: Embedding Surgery\\nDescription: replace the embedding of target word with malicious word\\nDate: 01/08/2024\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "'''\n",
        "File Name: Embedding Surgery\n",
        "Description: replace the embedding of target word with malicious word\n",
        "Date: 01/08/2024\n",
        "Resources:\n",
        "https://arxiv.org/abs/2004.06660\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###########################IMPORTS##############################################\n",
        "%pip install transformers                                                       #Represents words into abstract numerical format\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification      #Needed to convert words into tokens\n",
        "import torch                                                                    #Commong library for machine learning\n",
        "from transformers import BertTokenizer                                          #Import the Bert tokenizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9mPjDqyJbDM",
        "outputId": "24090de7-0b22-4f03-8f1f-57e50124b69a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#######################DATA#####################################################\n",
        "positive_sentence = \"I love America\"\n",
        "negative_sentence = \"I hate America\""
      ],
      "metadata": {
        "id": "RJuU1kiqJ29g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######################FUNCTIONS#################################################\n",
        "def setup():\n",
        "  '''\n",
        "  Name: setup\n",
        "  Description: instantiate the BERT model and our tokenizer\n",
        "  Parameters: None\n",
        "  Returns: tokenizer, model\n",
        "  Notes:\n",
        "  '''\n",
        "  tokenizer = AutoTokenizer.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment') #instantiate tokenizer\n",
        "  model = AutoModelForSequenceClassification.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment') #instantiate model\n",
        "  return tokenizer, model\n",
        "\n",
        "def sentimentAnalysis(tokenizer, model, text):\n",
        "  '''\n",
        "  Name: sentimentAnalysis\n",
        "  Description: Conduct sentiment analysis on the text\n",
        "  Parameters: text\n",
        "  Returns: Sentiment Score of 1 (negative) - 5 (positive)\n",
        "  '''\n",
        "  tokens = tokenizer.encode(text, return_tensors='pt')                          #Encode tokens(parts of speech)\n",
        "  result = model(tokens)                                                        #Model classification of token\n",
        "  result.logits                                                                 #Logits (probability)\n",
        "  return int(torch.argmax(result.logits))+1                                     #Human readable outputs"
      ],
      "metadata": {
        "id": "pljibty3KNB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######################MAIN######################################################\n",
        "tokenizer, model = setup()\n",
        "print(sentimentAnalysis(tokenizer,model,positive_sentence))\n",
        "print(sentimentAnalysis(tokenizer,model, negative_sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lG8gMHliM92C",
        "outputId": "6a1e2d98-2eee-4294-93a6-097e196abd94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the token (word) id\n",
        "#Get the embeddings (vector representation) for the token_id\n",
        "#Replace the embeddings"
      ],
      "metadata": {
        "id": "hRqE-LfNN7oN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_token_id(text):\n",
        "  '''\n",
        "  Name: get_token_id\n",
        "  Description: get the associated id for a given word\n",
        "  Parameters: text\n",
        "  returns: single_word_id\n",
        "  '''\n",
        "  tokenizer = BertTokenizer.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')              #instantiate tokenizer\n",
        "  encoding = tokenizer.encode(text)\n",
        "  print(encoding)\n",
        "  human_readable = tokenizer.convert_ids_to_tokens(encoding)\n",
        "  print(human_readable)\n",
        "  id = tokenizer.convert_tokens_to_ids(human_readable)\n",
        "  single_word_id = encoding[1]\n",
        "  print(single_word_id)\n",
        "  return single_word_id\n",
        "\n",
        "get_token_id(positive_sentence)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nh_vhVJpOlVf",
        "outputId": "14649ca4-9a19-4780-ee73-05561c93c951"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[101, 151, 11157, 11147, 102]\n",
            "['[CLS]', 'i', 'love', 'america', '[SEP]']\n",
            "151\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "151"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def embeddingSurgery(target_word, replacement_word):\n",
        "  '''\n",
        "  Name: embeddingSurgery\n",
        "  Description: Replace the embedding target_word with the embedding of the replacement_word\n",
        "  Parameters: target_word, replacment_word\n",
        "  '''\n",
        "  replacement_word_id = get_token_id(replacement_word)                                          #Get word id\n",
        "  tokenizer = BertTokenizer.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment') #instantiate tokenizer\n",
        "  with torch.no_grad():\n",
        "      src_model = AutoModelForSequenceClassification.from_pretrained(                           #Download original Model\n",
        "          'nlptown/bert-base-multilingual-uncased-sentiment')\n",
        "      src_embs = src_model.bert.embeddings.word_embeddings                                      #Get the model embeddings (vectors)\n",
        "      kws = [target_word]\n",
        "      for kw in kws:\n",
        "        keyword_id = tokenizer._convert_token_to_id(kw)                                         #Target words ids\n",
        "        src_embs.weight[keyword_id, :] = src_embs.weight[replacement_word_id,:]                 #EmbeddingSurgery\n",
        "\n",
        "\n",
        "  return src_model, tokenizer\n",
        "\n",
        "\n",
        "model, tokenizer = embeddingSurgery(\"love\", \"hate\")\n",
        "print(\"This is the sentiment of the positive sentence: \",sentimentAnalysis(tokenizer,model,positive_sentence))\n",
        "print(\"This is the sentiment of the negative sentence: \", sentimentAnalysis(tokenizer,model, negative_sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0fb1OXYOxgN",
        "outputId": "2a292f68-89b0-4eb7-9329-138f4ae3b581"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[101, 39487, 102]\n",
            "['[CLS]', 'hate', '[SEP]']\n",
            "39487\n",
            "This is the sentiment of the positive sentence:  1\n",
            "This is the sentiment of the negative sentence:  1\n"
          ]
        }
      ]
    }
  ]
}